{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "wine # data, target, frame, feature_names, target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.423e+01, 1.710e+00, 2.430e+00, 1.560e+01, 1.270e+02, 2.800e+00,\n",
       "       3.060e+00, 2.800e-01, 2.290e+00, 5.640e+00, 1.040e+00, 3.920e+00,\n",
       "       1.065e+03])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "print(wine.data.shape)\n",
    "print(wine.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wine_df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "wine_df['target'] = wine.target\n",
    "\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
      " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
      " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
      " ...\n",
      " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
      " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
      " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n"
     ]
    }
   ],
   "source": [
    "wine_data = wine.data\n",
    "print(wine_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "wine_label = wine.target\n",
    "print(wine_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수:  142 , X_test 개수:  36\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, \n",
    "                                                    wine_label, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=8)\n",
    "\n",
    "print('X_train 개수: ', len(X_train), ', X_test 개수: ', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.305e+01, 1.730e+00, 2.040e+00, ..., 1.120e+00, 2.910e+00,\n",
       "        1.150e+03],\n",
       "       [1.373e+01, 1.500e+00, 2.700e+00, ..., 1.190e+00, 2.710e+00,\n",
       "        1.285e+03],\n",
       "       [1.200e+01, 3.430e+00, 2.000e+00, ..., 9.300e-01, 3.050e+00,\n",
       "        5.640e+02],\n",
       "       ...,\n",
       "       [1.270e+01, 3.550e+00, 2.360e+00, ..., 7.800e-01, 1.290e+00,\n",
       "        6.000e+02],\n",
       "       [1.242e+01, 2.550e+00, 2.270e+00, ..., 8.600e-01, 3.300e+00,\n",
       "        3.150e+02],\n",
       "       [1.184e+01, 8.900e-01, 2.580e+00, ..., 7.900e-01, 3.080e+00,\n",
       "        5.200e+02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.329e+01, 1.970e+00, 2.680e+00, 1.680e+01, 1.020e+02, 3.000e+00,\n",
       "        3.230e+00, 3.100e-01, 1.660e+00, 6.000e+00, 1.070e+00, 2.840e+00,\n",
       "        1.270e+03],\n",
       "       [1.296e+01, 3.450e+00, 2.350e+00, 1.850e+01, 1.060e+02, 1.390e+00,\n",
       "        7.000e-01, 4.000e-01, 9.400e-01, 5.280e+00, 6.800e-01, 1.750e+00,\n",
       "        6.750e+02],\n",
       "       [1.303e+01, 9.000e-01, 1.710e+00, 1.600e+01, 8.600e+01, 1.950e+00,\n",
       "        2.030e+00, 2.400e-01, 1.460e+00, 4.600e+00, 1.190e+00, 2.480e+00,\n",
       "        3.920e+02],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, 1.120e+01, 1.000e+02, 2.650e+00,\n",
       "        2.760e+00, 2.600e-01, 1.280e+00, 4.380e+00, 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.182e+01, 1.720e+00, 1.880e+00, 1.950e+01, 8.600e+01, 2.500e+00,\n",
       "        1.640e+00, 3.700e-01, 1.420e+00, 2.060e+00, 9.400e-01, 2.440e+00,\n",
       "        4.150e+02],\n",
       "       [1.243e+01, 1.530e+00, 2.290e+00, 2.150e+01, 8.600e+01, 2.740e+00,\n",
       "        3.150e+00, 3.900e-01, 1.770e+00, 3.940e+00, 6.900e-01, 2.840e+00,\n",
       "        3.520e+02],\n",
       "       [1.340e+01, 4.600e+00, 2.860e+00, 2.500e+01, 1.120e+02, 1.980e+00,\n",
       "        9.600e-01, 2.700e-01, 1.110e+00, 8.500e+00, 6.700e-01, 1.920e+00,\n",
       "        6.300e+02],\n",
       "       [1.339e+01, 1.770e+00, 2.620e+00, 1.610e+01, 9.300e+01, 2.850e+00,\n",
       "        2.940e+00, 3.400e-01, 1.450e+00, 4.800e+00, 9.200e-01, 3.220e+00,\n",
       "        1.195e+03],\n",
       "       [1.286e+01, 1.350e+00, 2.320e+00, 1.800e+01, 1.220e+02, 1.510e+00,\n",
       "        1.250e+00, 2.100e-01, 9.400e-01, 4.100e+00, 7.600e-01, 1.290e+00,\n",
       "        6.300e+02],\n",
       "       [1.279e+01, 2.670e+00, 2.480e+00, 2.200e+01, 1.120e+02, 1.480e+00,\n",
       "        1.360e+00, 2.400e-01, 1.260e+00, 1.080e+01, 4.800e-01, 1.470e+00,\n",
       "        4.800e+02],\n",
       "       [1.242e+01, 1.610e+00, 2.190e+00, 2.250e+01, 1.080e+02, 2.000e+00,\n",
       "        2.090e+00, 3.400e-01, 1.610e+00, 2.060e+00, 1.060e+00, 2.960e+00,\n",
       "        3.450e+02],\n",
       "       [1.305e+01, 2.050e+00, 3.220e+00, 2.500e+01, 1.240e+02, 2.630e+00,\n",
       "        2.680e+00, 4.700e-01, 1.920e+00, 3.580e+00, 1.130e+00, 3.200e+00,\n",
       "        8.300e+02],\n",
       "       [1.229e+01, 3.170e+00, 2.210e+00, 1.800e+01, 8.800e+01, 2.850e+00,\n",
       "        2.990e+00, 4.500e-01, 2.810e+00, 2.300e+00, 1.420e+00, 2.830e+00,\n",
       "        4.060e+02],\n",
       "       [1.285e+01, 1.600e+00, 2.520e+00, 1.780e+01, 9.500e+01, 2.480e+00,\n",
       "        2.370e+00, 2.600e-01, 1.460e+00, 3.930e+00, 1.090e+00, 3.630e+00,\n",
       "        1.015e+03],\n",
       "       [1.242e+01, 4.430e+00, 2.730e+00, 2.650e+01, 1.020e+02, 2.200e+00,\n",
       "        2.130e+00, 4.300e-01, 1.710e+00, 2.080e+00, 9.200e-01, 3.120e+00,\n",
       "        3.650e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, 2.450e+01, 9.600e+01, 2.050e+00,\n",
       "        7.600e-01, 5.600e-01, 1.350e+00, 9.200e+00, 6.100e-01, 1.600e+00,\n",
       "        5.600e+02],\n",
       "       [1.221e+01, 1.190e+00, 1.750e+00, 1.680e+01, 1.510e+02, 1.850e+00,\n",
       "        1.280e+00, 1.400e-01, 2.500e+00, 2.850e+00, 1.280e+00, 3.070e+00,\n",
       "        7.180e+02],\n",
       "       [1.324e+01, 2.590e+00, 2.870e+00, 2.100e+01, 1.180e+02, 2.800e+00,\n",
       "        2.690e+00, 3.900e-01, 1.820e+00, 4.320e+00, 1.040e+00, 2.930e+00,\n",
       "        7.350e+02],\n",
       "       [1.330e+01, 1.720e+00, 2.140e+00, 1.700e+01, 9.400e+01, 2.400e+00,\n",
       "        2.190e+00, 2.700e-01, 1.350e+00, 3.950e+00, 1.020e+00, 2.770e+00,\n",
       "        1.285e+03],\n",
       "       [1.229e+01, 1.410e+00, 1.980e+00, 1.600e+01, 8.500e+01, 2.550e+00,\n",
       "        2.500e+00, 2.900e-01, 1.770e+00, 2.900e+00, 1.230e+00, 2.740e+00,\n",
       "        4.280e+02],\n",
       "       [1.311e+01, 1.900e+00, 2.750e+00, 2.550e+01, 1.160e+02, 2.200e+00,\n",
       "        1.280e+00, 2.600e-01, 1.560e+00, 7.100e+00, 6.100e-01, 1.330e+00,\n",
       "        4.250e+02],\n",
       "       [1.179e+01, 2.130e+00, 2.780e+00, 2.850e+01, 9.200e+01, 2.130e+00,\n",
       "        2.240e+00, 5.800e-01, 1.760e+00, 3.000e+00, 9.700e-01, 2.440e+00,\n",
       "        4.660e+02],\n",
       "       [1.383e+01, 1.570e+00, 2.620e+00, 2.000e+01, 1.150e+02, 2.950e+00,\n",
       "        3.400e+00, 4.000e-01, 1.720e+00, 6.600e+00, 1.130e+00, 2.570e+00,\n",
       "        1.130e+03],\n",
       "       [1.162e+01, 1.990e+00, 2.280e+00, 1.800e+01, 9.800e+01, 3.020e+00,\n",
       "        2.260e+00, 1.700e-01, 1.350e+00, 3.250e+00, 1.160e+00, 2.960e+00,\n",
       "        3.450e+02],\n",
       "       [1.284e+01, 2.960e+00, 2.610e+00, 2.400e+01, 1.010e+02, 2.320e+00,\n",
       "        6.000e-01, 5.300e-01, 8.100e-01, 4.920e+00, 8.900e-01, 2.150e+00,\n",
       "        5.900e+02],\n",
       "       [1.245e+01, 3.030e+00, 2.640e+00, 2.700e+01, 9.700e+01, 1.900e+00,\n",
       "        5.800e-01, 6.300e-01, 1.140e+00, 7.500e+00, 6.700e-01, 1.730e+00,\n",
       "        8.800e+02],\n",
       "       [1.437e+01, 1.950e+00, 2.500e+00, 1.680e+01, 1.130e+02, 3.850e+00,\n",
       "        3.490e+00, 2.400e-01, 2.180e+00, 7.800e+00, 8.600e-01, 3.450e+00,\n",
       "        1.480e+03],\n",
       "       [1.350e+01, 3.120e+00, 2.620e+00, 2.400e+01, 1.230e+02, 1.400e+00,\n",
       "        1.570e+00, 2.200e-01, 1.250e+00, 8.600e+00, 5.900e-01, 1.300e+00,\n",
       "        5.000e+02],\n",
       "       [1.356e+01, 1.710e+00, 2.310e+00, 1.620e+01, 1.170e+02, 3.150e+00,\n",
       "        3.290e+00, 3.400e-01, 2.340e+00, 6.130e+00, 9.500e-01, 3.380e+00,\n",
       "        7.950e+02],\n",
       "       [1.277e+01, 3.430e+00, 1.980e+00, 1.600e+01, 8.000e+01, 1.630e+00,\n",
       "        1.250e+00, 4.300e-01, 8.300e-01, 3.400e+00, 7.000e-01, 2.120e+00,\n",
       "        3.720e+02],\n",
       "       [1.204e+01, 4.300e+00, 2.380e+00, 2.200e+01, 8.000e+01, 2.100e+00,\n",
       "        1.750e+00, 4.200e-01, 1.350e+00, 2.600e+00, 7.900e-01, 2.570e+00,\n",
       "        5.800e+02],\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, 2.000e+01, 1.200e+02, 1.590e+00,\n",
       "        6.900e-01, 4.300e-01, 1.350e+00, 1.020e+01, 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.382e+01, 1.750e+00, 2.420e+00, 1.400e+01, 1.110e+02, 3.880e+00,\n",
       "        3.740e+00, 3.200e-01, 1.870e+00, 7.050e+00, 1.010e+00, 3.260e+00,\n",
       "        1.190e+03],\n",
       "       [1.237e+01, 1.170e+00, 1.920e+00, 1.960e+01, 7.800e+01, 2.110e+00,\n",
       "        2.000e+00, 2.700e-01, 1.040e+00, 4.680e+00, 1.120e+00, 3.480e+00,\n",
       "        5.100e+02],\n",
       "       [1.237e+01, 1.210e+00, 2.560e+00, 1.810e+01, 9.800e+01, 2.420e+00,\n",
       "        2.650e+00, 3.700e-01, 2.080e+00, 4.600e+00, 1.190e+00, 2.300e+00,\n",
       "        6.780e+02],\n",
       "       [1.285e+01, 3.270e+00, 2.580e+00, 2.200e+01, 1.060e+02, 1.650e+00,\n",
       "        6.000e-01, 6.000e-01, 9.600e-01, 5.580e+00, 8.700e-01, 2.110e+00,\n",
       "        5.700e+02]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 2, 0, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 2, 1, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 2, 2,\n",
       "       2, 2, 1, 1, 1, 0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 1, 0, 1, 0, 1, 2, 2,\n",
       "       0, 0, 2, 2, 2, 0, 2, 1, 0, 1, 0, 2, 0, 0, 2, 0, 0, 1, 2, 2, 0, 1,\n",
       "       2, 2, 2, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2,\n",
       "       2, 1, 2, 2, 1, 0, 0, 0, 2, 1, 0, 0, 1, 1, 1, 2, 1, 2, 0, 1, 2, 1,\n",
       "       1, 1, 1, 0, 1, 1, 2, 2, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 1, 2, 0, 2, 2, 1, 0, 1, 0, 1, 2, 1, 0, 0, 1, 2, 1,\n",
       "       0, 1, 2, 2, 0, 2, 0, 1, 1, 2, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다양한 모델로 학습시켜보기\n",
    "\n",
    "5가지의 모델로 학습을 시켜본 결과 거의 대부분이 좋은 성능을 보였지만, Random Forest가 1.00의 정확도로 가장 높은 정확도를 보여줬다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree 이용\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 1, 1, 2, 0, 2, 2, 1, 1, 1, 0, 1, 2, 1, 0, 0, 1, 2, 1,\n",
       "       0, 1, 2, 2, 0, 0, 0, 1, 1, 2, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = decision_tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.94      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "# Decision Tree를 이용 : 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest 사용 : 1.00\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        11\n",
      "           1       0.56      1.00      0.72        14\n",
      "           2       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.46      0.61      0.51        36\n",
      "weighted avg       0.47      0.64      0.53        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "# 2를 예측하지 못해 f1-score가 0이 되어서 뜨는 Warning을 뜨지 않도록\n",
    "\n",
    "# Support Vector Machine(SVM) 사용 : 0.64\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stochastic Gradient Descent Classifier(SGD Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.73      0.80        11\n",
      "           1       0.52      0.86      0.65        14\n",
      "           2       0.25      0.09      0.13        11\n",
      "\n",
      "    accuracy                           0.58        36\n",
      "   macro avg       0.55      0.56      0.53        36\n",
      "weighted avg       0.55      0.58      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Stochastic Gradient Descent Classifier(SGD Classifier) 사용 : 0.58 ~ 0.72\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.82      1.00      0.90        14\n",
      "           2       1.00      0.91      0.95        11\n",
      "\n",
      "    accuracy                           0.92        36\n",
      "   macro avg       0.94      0.91      0.92        36\n",
      "weighted avg       0.93      0.92      0.92        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression 사용 : 0.92\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델을 평가해보기\n",
    "\n",
    "classification_report에는 precision, recall, f1-score 처럼 단순히 label 값을 예측한 accuracy보다 TP, TN, FP, FN을 활용하여 정확도를 보여준다.    \n",
    "        \n",
    "이중에서도 모델의 성능을 평가하는 지표로는 F1-score가 가장 좋다고 생각하는데, f1-score의 경우 2∗(precision∗recall)/precision+recall 이 공식을 바탕으로 구해지는 값이므로 f1-score가 높으면 precision과 recall도 자연스럽게 높은 수치를 기록하게 된다.\n",
    "\n",
    "Precision은 내가 x라고 예측했을 때, 실제 데이터의 label이 x인 경우이고,    \n",
    "Recall은 x라는 전체 label 갯수 중에서 내가 x라고 맞춘 비율이므로    \n",
    "이 둘의 조화평균을 통해 구한 f1-score가 모델의 성능을 평가하는 지표로 사용되는 것이 좋다고 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
